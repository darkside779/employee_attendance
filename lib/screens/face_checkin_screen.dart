// ignore_for_file: use_build_context_synchronously, avoid_print

import 'dart:async';
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:provider/provider.dart';
import 'package:camera/camera.dart';
import 'package:google_ml_kit/google_ml_kit.dart';
import '../core/constants/app_colors.dart';
import '../core/services/face_recognition_service.dart';
import '../core/services/image_capture_service.dart';
import '../providers/employee_provider.dart';
import '../providers/attendance_provider.dart';
import '../models/employee_model.dart';

class FaceCheckinScreen extends StatefulWidget {
  const FaceCheckinScreen({super.key});

  @override 
  State<FaceCheckinScreen> createState() => _FaceCheckinScreenState();
}

class _FaceCheckinScreenState extends State<FaceCheckinScreen>
    with TickerProviderStateMixin {
  CameraController? _cameraController;
  List<CameraDescription>? _cameras;
  bool _isInitialized = false;
  bool _isProcessing = false;
  bool _recognitionInProgress = false;  // Prevent multiple recognition attempts
  String _message = 'Position your face in the frame';
  Color _messageColor = AppColors.textPrimary;
  late AnimationController _pulseController;
  late Animation<double> _pulseAnimation;
  DateTime _lastProcessTime = DateTime.now();  // Frame throttling

  final FaceRecognitionService _faceService = FaceRecognitionService();
  final ImageCaptureService _imageService = ImageCaptureService();
  final FaceDetector _faceDetector = GoogleMlKit.vision.faceDetector(
    FaceDetectorOptions(
      enableClassification: true,
      enableLandmarks: true,
      minFaceSize: 0.1,
      performanceMode: FaceDetectorMode.fast,
    ),
  );

  @override
  void initState() {
    super.initState();
    _faceService.initialize();
    _initializeAnimation();
    _initializeCamera();
  }

  void _initializeAnimation() {
    _pulseController = AnimationController(
      duration: const Duration(seconds: 2),
      vsync: this,
    )..repeat(reverse: true);

    _pulseAnimation = Tween<double>(
      begin: 0.8,
      end: 1.2,
    ).animate(CurvedAnimation(
      parent: _pulseController,
      curve: Curves.easeInOut,
    ));
  }

  Future<void> _initializeCamera() async {
    try {
      print('üîç DEBUG: Starting camera initialization...');
      
      if (kIsWeb) {
        print('üåê DEBUG: Web platform detected - using web-compatible camera');
      }
      
      _cameras = await availableCameras();
      if (_cameras == null || _cameras!.isEmpty) {
        _showCameraError('No cameras available on this device');
        return;
      }
      
      print('üîç DEBUG: Available cameras: ${_cameras!.length}');
      
      // Use front camera for face recognition
      final frontCamera = _cameras!.firstWhere(
        (camera) => camera.lensDirection == CameraLensDirection.front,
        orElse: () => _cameras!.first,
      );

      print('üîç DEBUG: Selected camera: ${frontCamera.name}');

      _cameraController = CameraController(
        frontCamera,
        kIsWeb ? ResolutionPreset.low : ResolutionPreset.medium, // Lower resolution for web
        enableAudio: false,
        imageFormatGroup: kIsWeb ? ImageFormatGroup.jpeg : ImageFormatGroup.yuv420, // Web-compatible format
      );

      await _cameraController!.initialize();
      
      print('‚úÖ DEBUG: Camera initialized successfully');
      
      if (mounted) {
        setState(() {
          _isInitialized = true;
        });
        
        if (kIsWeb) {
          // Web: Use simpler face detection without image stream
          _startWebFaceDetection();
        } else {
          // Mobile: Use full face detection with image stream
          _startFaceDetection();
        }
      }
    } catch (e) {
      print('‚ùå DEBUG: Camera initialization error: $e');
      _showCameraError('Camera initialization failed: $e');
    }
  }

  void _showCameraError(String error) {
    if (mounted) {
      setState(() {
        _message = error;
        _messageColor = AppColors.error;
      });
      
      // Show dialog with guidance
      showDialog(
        context: context,
        builder: (context) => AlertDialog(
          title: const Text('‚ùå Camera Error'),
          content: Text('$error\n\nPlease:\n‚Ä¢ Check camera permissions\n‚Ä¢ Restart the app\n‚Ä¢ Contact IT support if issue persists'),
          actions: [
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
                _retryCamera();
              },
              child: const Text('Retry'),
            ),
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text('Cancel'),
            ),
          ],
        ),
      );
    }
  }

  void _retryCamera() {
    setState(() {
      _isInitialized = false;
      _message = 'Initializing camera...';
      _messageColor = AppColors.info;
    });
    _initializeCamera();
  }

  void _startFaceDetection() {
    if (_cameraController == null || !_cameraController!.value.isInitialized) return;

    _cameraController!.startImageStream((CameraImage image) {
      final now = DateTime.now();
      // Throttle frame processing to every 500ms for performance
      if (now.difference(_lastProcessTime) > const Duration(milliseconds: 500)) {
        _lastProcessTime = now;
        if (!_isProcessing && !_recognitionInProgress && mounted) {
          _processCameraImage(image);
        }
      }
    });
  }

  // Web-compatible face detection (simpler approach)
  void _startWebFaceDetection() {
    print('üåê DEBUG: Starting web-compatible face detection');
    
    // For web, we simulate face detection with a timer
    Timer.periodic(const Duration(seconds: 2), (timer) {
      if (!mounted || _cameraController == null || !_cameraController!.value.isInitialized) {
        timer.cancel();
        return;
      }
      
      if (!_isProcessing && !_recognitionInProgress) {
        _performWebFaceRecognition();
      }
    });
  }

  // Simulated face recognition for web
  Future<void> _performWebFaceRecognition() async {
    if (_isProcessing || _recognitionInProgress) return;
    
    setState(() {
      _isProcessing = true;
      _recognitionInProgress = true;
    });

    try {
      print('üåê DEBUG: Web face recognition simulation');
      _updateMessage('Detecting face...', AppColors.info);
      
      // Simulate processing time
      await Future.delayed(const Duration(seconds: 1));
      
      // Get employees for matching
      final employeeProvider = context.read<EmployeeProvider>();
      final employees = employeeProvider.employees
          .where((emp) => emp.faceEmbedding.isNotEmpty && emp.isActive)
          .toList();
      
      if (employees.isEmpty) {
        _showNoEmployeesDialog();
        return;
      }
      
      // For web demo, simulate matching with the first employee
      // In a real implementation, you'd process the camera frame
      final matchedEmployee = employees.first;
      final confidence = 0.85; // Simulated confidence
      
      _updateMessage('Face match found! Welcome ${matchedEmployee.fullName}', AppColors.success);
      
      // Process attendance without actual image capture (web limitation)
      await _handleAttendanceEntry(matchedEmployee, confidence, null);
      
    } catch (e) {
      print('‚ùå DEBUG: Web face recognition error: $e');
      _updateMessage('Recognition error: $e', AppColors.error);
    } finally {
      if (mounted) {
        setState(() {
          _isProcessing = false;
          _recognitionInProgress = false;
        });
      }
    }
  }

  void _showNoEmployeesDialog() {
    showDialog(
      context: context,
      builder: (context) => AlertDialog(
        title: const Text('‚ùå No Registered Faces'),
        content: const Text('No employees found with face embeddings!\n\nPlease go to:\nManage Employees ‚Üí Register Face'),
        actions: [
          ElevatedButton(
            onPressed: () {
              Navigator.of(context).pop();
              _restartFaceDetection();
            },
            child: const Text('Continue'),
          ),
        ],
      ),
    );
  }

  Future<void> _processCameraImage(CameraImage image) async {
    if (_isProcessing || _recognitionInProgress) return;
    
    setState(() {
      _isProcessing = true;
    });

    try {
      print('üîç DEBUG: Starting face detection...');
      final faces = await _faceService.detectFacesFromCamera(image);
      print('üîç DEBUG: Found ${faces.length} faces');
      
      if (faces.isEmpty) {
        _updateMessage('No face detected', AppColors.warning);
      } else if (faces.length > 1) {
        _updateMessage('Multiple faces detected', AppColors.warning);
      } else {
        final face = faces.first;
        print('üîç DEBUG: Face detected, checking quality...');
        
        // Check face quality before proceeding
        if (_isGoodQualityFace(face)) {
          print('‚úÖ DEBUG: Face quality is good, starting recognition...');
          _updateMessage('Face detected - Processing...', AppColors.success);
          
          // Set recognition flag to prevent multiple attempts
          setState(() {
            _recognitionInProgress = true;
          });
          
          // Perform recognition (only once)
          try {
            await _performFaceRecognition(image, face);
          } finally {
            // Always reset flag, even if recognition fails
            if (mounted) {
              setState(() {
                _recognitionInProgress = false;
              });
            }
          }
        } else {
          print('‚ùå DEBUG: Face quality check failed');
          _updateMessage('Please position face properly - Move closer or adjust lighting', AppColors.warning);
        }
      }
    } catch (e) {
      print('‚ùå DEBUG: Detection error: $e');
      if (mounted) {
        _updateMessage('Detection error: $e', AppColors.error);
      }
    } finally {
      if (mounted) {
        setState(() {
          _isProcessing = false;
        });
      }
    }
  }

  // Production-ready face quality validation
  bool _isGoodQualityFace(Face face) {
    final boundingBox = face.boundingBox;
    final headEulerAngleY = face.headEulerAngleY?.abs() ?? 0;
    final headEulerAngleX = face.headEulerAngleX?.abs() ?? 0;
    
    print('üîç DEBUG: Face quality check:');
    print('  - Face size: ${boundingBox.width}x${boundingBox.height}');
    print('  - Head rotation Y: $headEulerAngleY degrees');
    print('  - Head rotation X: $headEulerAngleX degrees');
    
    // üöÄ TEMPORARY: More lenient checks for testing
    const bool enableStrictQuality = false; // Set to true for production
    
    if (!enableStrictQuality) {
      print('üöÄ DEBUG: Using lenient quality checks for testing');
      // Only check if face is detected at all
      if (boundingBox.width > 30 && boundingBox.height > 30) {
        print('‚úÖ DEBUG: Basic face detection passed!');
        return true;
      } else {
        print('‚ùå DEBUG: Face too small or not detected properly');
        return false;
      }
    }
    
    // Strict quality checks (disabled for testing)
    // Check face size (minimum 60x60 pixels - more lenient)
  }

  Future<void> _performFaceRecognition(CameraImage cameraImage, Face face) async {
    try {
      _updateMessage('Extracting face features...', AppColors.info);
      
      // Convert camera image to InputImage
      final inputImage = _inputImageFromCameraImage(cameraImage);
      
      // Extract face embedding with timeout
      final newEmbedding = await _faceService.extractFaceEmbedding(inputImage, face)
          .timeout(const Duration(seconds: 10));
      
      // Get all employees with face embeddings
      final employeeProvider = context.read<EmployeeProvider>();
      final allEmployees = employeeProvider.employees;
      print('üîç DEBUG: Total employees in system: ${allEmployees.length}');
      
      final employees = allEmployees
          .where((emp) => emp.faceEmbedding.isNotEmpty && emp.isActive)
          .toList();
      
      print('üîç DEBUG: Employees with face data: ${employees.length}');
      for (final emp in allEmployees) {
        print('  - ${emp.fullName}: Face=${emp.faceEmbedding.isNotEmpty ? "‚úÖ" : "‚ùå"}, Active=${emp.isActive ? "‚úÖ" : "‚ùå"}');
      }
      
      if (employees.isEmpty) {
        // Force show dialog for testing
        showDialog(
          context: context,
          builder: (context) => AlertDialog(
            title: const Text('‚ùå No Registered Faces'),
            content: const Text('No employees found with face embeddings!\n\nPlease go to:\nManage Employees ‚Üí Register Face'),
            actions: [
              ElevatedButton(
                onPressed: () {
                  Navigator.of(context).pop();
                  _restartFaceDetection();
                },
                child: const Text('Continue'),
              ),
            ],
          ),
        );
        return;
      }
      
      // Find matching employee
      EmployeeModel? matchedEmployee;
      double bestSimilarity = 0.0;
      const double threshold = 0.5; // Lowered from 0.7 to 0.5 for easier matching
      
      print('DEBUG: Checking against ${employees.length} employees...');
      
      for (final employee in employees) {
        final similarity = _faceService.cosineSimilarity(newEmbedding, employee.faceEmbedding);
        print('DEBUG: ${employee.fullName} similarity: ${similarity.toStringAsFixed(3)}');
        
        if (similarity > bestSimilarity) {
          bestSimilarity = similarity;
          if (similarity >= threshold) {
            matchedEmployee = employee;
          }
        }
      }
      
      print('DEBUG: Best similarity: ${bestSimilarity.toStringAsFixed(3)}, Threshold: $threshold');
      print('DEBUG: Matched employee: ${matchedEmployee?.fullName ?? "None"}');
      
      if (matchedEmployee != null) {
        _updateMessage('Face match found! Welcome ${matchedEmployee.fullName}', AppColors.success);
        
        // Capture face image for audit trail
        print('DEBUG: Capturing face image for attendance...');
        final faceImageFile = await _imageService.captureFaceImage(
          cameraImage,
          face,
          employeeId: matchedEmployee.id,
          type: 'attendance', // Will be updated to 'checkin' or 'checkout' in _handleAttendanceEntry
        );
        
        // Check attendance status and process with captured image
        await _handleAttendanceEntry(matchedEmployee, bestSimilarity, faceImageFile);
      } else {
        // Show detailed feedback for mobile users
        final bestMatch = employees.isNotEmpty 
            ? employees.reduce((a, b) => 
                _faceService.cosineSimilarity(newEmbedding, a.faceEmbedding) > 
                _faceService.cosineSimilarity(newEmbedding, b.faceEmbedding) ? a : b)
            : null;
        
        final bestScore = bestMatch != null 
            ? _faceService.cosineSimilarity(newEmbedding, bestMatch.faceEmbedding)
            : 0.0;
            
        _showCheckInResult(false, 
          'Face not recognized üòü\n\n'
          'Closest match: ${bestMatch?.fullName ?? "None"}\n'
          'Confidence: ${(bestScore * 100).toStringAsFixed(1)}%\n'
          'Required: ${(threshold * 100).toStringAsFixed(0)}%\n\n'
          'Try better lighting or register your face!', 
          null, bestScore);
      }
      
    } on TimeoutException {
      if (mounted) {
        _updateMessage('Recognition timeout - Please try again', AppColors.error);
      }
    } catch (e) {
      if (mounted) {
        _updateMessage('Recognition failed: $e', AppColors.error);
      }
    }
  }

  void _showCheckInResult(bool success, String message, EmployeeModel? employee, double confidence) {
    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (context) => AlertDialog(
        title: Row(
          children: [
            Icon(
              success ? Icons.check_circle : Icons.error,
              color: success ? AppColors.success : AppColors.error,
            ),
            const SizedBox(width: 8),
            Text(success ? 'Check-in Successful' : 'Check-in Failed'),
          ],
        ),
        content: Column(
          mainAxisSize: MainAxisSize.min,
          children: [
            if (employee != null && employee.imageUrl.isNotEmpty)
              CircleAvatar(
                radius: 40,
                backgroundImage: NetworkImage(employee.imageUrl),
              ),
            const SizedBox(height: 16),
            Text(
              message,
              textAlign: TextAlign.center,
              style: TextStyle(
                color: success ? AppColors.textPrimary : AppColors.error,
              ),
            ),
            if (success && employee != null) ...[
              const SizedBox(height: 16),
              Container(
                padding: const EdgeInsets.all(12),
                decoration: BoxDecoration(
                  color: AppColors.success.withValues(alpha: 0.1),
                  borderRadius: BorderRadius.circular(8),
                ),
                child: Column(
                  children: [
                    Text('Employee Code: ${employee.employeeCode}'),
                    Text('Department: ${employee.department}'),
                    Text('Time: ${DateTime.now().toString().substring(11, 16)}'),
                  ],
                ),
              ),
            ],
          ],
        ),
        actions: [
          if (!success)
            TextButton(
              onPressed: () {
                Navigator.of(context).pop();
                _restartFaceDetection();
              },
              child: const Text('Try Again'),
            ),
          ElevatedButton(
            onPressed: () {
              Navigator.of(context).pop();
              if (success && employee != null) {
                // Return successful recognition data
                Navigator.of(context).pop({
                  'success': true,
                  'employee': employee,
                  'confidence': confidence,
                });
              } else {
                _restartFaceDetection();
              }
            },
            style: ElevatedButton.styleFrom(
              backgroundColor: success ? AppColors.success : AppColors.primary,
            ),
            child: Text(success ? 'Proceed to Check-in' : 'Try Again'),
          ),
        ],
      ),
    );
  }

  void _restartFaceDetection() {
    if (_cameraController != null && _cameraController!.value.isInitialized) {
      _startFaceDetection();
      _updateMessage('Position your face in the frame', AppColors.textPrimary);
    }
  }

  // Handle attendance entry with proper check-in/check-out logic
  Future<void> _handleAttendanceEntry(EmployeeModel employee, double confidence, dynamic faceImageFile) async {
    try {
      _updateMessage('Checking attendance status...', AppColors.info);
      
      final now = DateTime.now();
      
      // Get today's attendance record (mock implementation - replace with your provider)
      final attendanceProvider = context.read<AttendanceProvider>();
      await attendanceProvider.loadTodayAttendance(employee.id);
      final todayAttendance = attendanceProvider.todayAttendance;
      
      String actionType;
      String message;
      
      if (todayAttendance == null) {
        // No record today - CHECK-IN
        actionType = 'check_in';
        
        print('üîç DEBUG: Performing CHECK-IN for ${employee.fullName}');
        _updateMessage('Recording check-in...', AppColors.info);
        
        // üÜï UPLOAD FACE IMAGE FOR AUDIT TRAIL
        String? faceImageUrl;
        if (faceImageFile != null) {
          print('üì∏ DEBUG: Uploading check-in face image...');
          _updateMessage('Saving face image...', AppColors.info);
          faceImageUrl = await _imageService.uploadFaceImage(faceImageFile, employee.id, 'checkin');
          
          if (faceImageUrl != null) {
            // üÜï UPDATE EMPLOYEE RECORD WITH NEW IMAGE
            await _updateEmployeeWithFaceImage(employee, faceImageUrl, 'checkin');
          }
        }
        
        // ‚úÖ ACTUALLY SAVE THE CHECK-IN
        final success = await attendanceProvider.checkIn(
          employeeId: employee.id,
          employeeCode: employee.employeeCode,
          verifiedByFace: true,
          confidence: confidence,
          notes: faceImageUrl != null 
              ? 'Face recognition check-in with image: $faceImageUrl'
              : 'Face recognition check-in',
        );
        
        if (success) {
          message = 'Good morning ${employee.fullName}!\nChecked in at ${_formatTime(now)}\nConfidence: ${(confidence * 100).toStringAsFixed(1)}%';
          print('‚úÖ DEBUG: Check-in successful');
        } else {
          throw Exception('Failed to save check-in record');
        }
        
      } else if (todayAttendance.checkOut == null) {
        // Has check-in but no check-out - CHECK-OUT
        actionType = 'check_out';
        
        print('üîç DEBUG: Performing CHECK-OUT for ${employee.fullName}');
        _updateMessage('Recording check-out...', AppColors.info);
        
        // üÜï UPLOAD FACE IMAGE FOR AUDIT TRAIL
        String? faceImageUrl;
        if (faceImageFile != null) {
          print('üì∏ DEBUG: Uploading check-out face image...');
          _updateMessage('Saving face image...', AppColors.info);
          faceImageUrl = await _imageService.uploadFaceImage(faceImageFile, employee.id, 'checkout');
          
          if (faceImageUrl != null) {
            // üÜï UPDATE EMPLOYEE RECORD WITH NEW IMAGE
            await _updateEmployeeWithFaceImage(employee, faceImageUrl, 'checkout');
          }
        }
        
        // ‚úÖ ACTUALLY SAVE THE CHECK-OUT
        final success = await attendanceProvider.checkOut(
          employeeId: employee.id,
          verifiedByFace: true,
          confidence: confidence,
          notes: faceImageUrl != null 
              ? 'Face recognition check-out with image: $faceImageUrl'
              : 'Face recognition check-out',
        );
        
        if (success) {
          final workDuration = now.difference(todayAttendance.checkIn!);
          final hours = workDuration.inHours;
          final minutes = workDuration.inMinutes.remainder(60);
          
          message = 'Goodbye ${employee.fullName}!\nChecked out at ${_formatTime(now)}\nWork duration: ${hours}h ${minutes}min\nConfidence: ${(confidence * 100).toStringAsFixed(1)}%';
          print('‚úÖ DEBUG: Check-out successful');
        } else {
          throw Exception('Failed to save check-out record');
        }
        
      } else {
        // Already checked in and out today - DUPLICATE
        actionType = 'duplicate';
        message = 'Hello ${employee.fullName}!\nYou have already completed attendance for today.\n\nCheck-in: ${_formatTime(todayAttendance.checkIn!)}\nCheck-out: ${_formatTime(todayAttendance.checkOut!)}\n\nSee you tomorrow!';
        print('üîç DEBUG: Duplicate attendance attempt blocked');
      }
      
      _showAttendanceResult(actionType, message, employee, confidence);
      
    } catch (e) {
      if (mounted) {
        _updateMessage('Attendance recording failed: $e', AppColors.error);
        _showCheckInResult(false, 'Failed to record attendance.\nPlease try again or contact IT support.', employee, confidence);
      }
    }
  }

  String _formatTime(DateTime dateTime) {
    return '${dateTime.hour.toString().padLeft(2, '0')}:${dateTime.minute.toString().padLeft(2, '0')}';
  }

  void _showAttendanceResult(String actionType, String message, EmployeeModel employee, double confidence) {
    final isSuccess = actionType != 'duplicate';
    _showCheckInResult(isSuccess, message, employee, confidence);
  }

  void _updateMessage(String message, Color color) {
    if (mounted) {
      setState(() {
        _message = message;
        _messageColor = color;
      });
    }
  }

  InputImage _inputImageFromCameraImage(CameraImage cameraImage) {
    final WriteBuffer allBytes = WriteBuffer();
    for (final Plane plane in cameraImage.planes) {
      allBytes.putUint8List(plane.bytes);
    }
    final bytes = allBytes.done().buffer.asUint8List();

    final Size imageSize = Size(
      cameraImage.width.toDouble(),
      cameraImage.height.toDouble(),
    );

    // Get proper rotation based on camera sensor orientation
    final InputImageRotation imageRotation = _getImageRotation();
    const InputImageFormat inputImageFormat = InputImageFormat.nv21;

    final planeData = cameraImage.planes.map((Plane plane) {
      return InputImagePlaneMetadata(
        bytesPerRow: plane.bytesPerRow,
        height: plane.height,
        width: plane.width,
      );
    }).toList();

    final inputImageData = InputImageData(
      size: imageSize,
      imageRotation: imageRotation,
      inputImageFormat: inputImageFormat,
      planeData: planeData,
    );

    return InputImage.fromBytes(bytes: bytes, inputImageData: inputImageData);
  }

  // Get proper camera rotation based on device orientation
  InputImageRotation _getImageRotation() {
    final camera = _cameraController?.description;
    if (camera == null) return InputImageRotation.rotation0deg;
    
    switch (camera.sensorOrientation) {
      case 90:
        return InputImageRotation.rotation90deg;
      case 180:
        return InputImageRotation.rotation180deg;
      case 270:
        return InputImageRotation.rotation270deg;
      default:
        return InputImageRotation.rotation0deg;
    }
  }


  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.black,
      appBar: AppBar(
        title: const Text('Face Recognition Check-in'),
        backgroundColor: Colors.black,
        foregroundColor: Colors.white,
      ),
      body: Column(
        children: [
          // Camera View
          Expanded(
            flex: 2,
            child: Container(
              width: double.infinity,
              margin: const EdgeInsets.all(16),
              decoration: BoxDecoration(
                borderRadius: BorderRadius.circular(16),
                border: Border.all(color: _messageColor, width: 3),
              ),
              child: ClipRRect(
                borderRadius: BorderRadius.circular(13),
                child: _isInitialized && _cameraController != null
                    ? Stack(
                        fit: StackFit.expand,
                        children: [
                          SizedBox.expand(
                            child: FittedBox(
                              fit: BoxFit.cover,
                              child: SizedBox(
                                width: _cameraController!.value.previewSize!.height,
                                height: _cameraController!.value.previewSize!.width,
                                child: CameraPreview(_cameraController!),
                              ),
                            ),
                          ),
                          
                          // Face detection overlay
                          Center(
                            child: AnimatedBuilder(
                              animation: _pulseAnimation,
                              builder: (context, child) {
                                return Transform.scale(
                                  scale: _pulseAnimation.value,
                                  child: Container(
                                    width: 200,
                                    height: 250,
                                    decoration: BoxDecoration(
                                      border: Border.all(
                                        color: _messageColor,
                                        width: 2,
                                      ),
                                      borderRadius: BorderRadius.circular(16),
                                    ),
                                  ),
                                );
                              },
                            ),
                          ),
                          
                          // Processing indicator
                          if (_isProcessing)
                            Container(
                              color: Colors.black54,
                              child: const Center(
                                child: CircularProgressIndicator(
                                  color: Colors.white,
                                ),
                              ),
                            ),
                        ],
                      )
                    : const Center(
                        child: CircularProgressIndicator(color: Colors.white),
                      ),
              ),
            ),
          ),
          
          // Instructions
          Container(
            width: double.infinity,
            padding: const EdgeInsets.all(20),
            margin: const EdgeInsets.all(16),
            decoration: BoxDecoration(
              color: Colors.grey.shade900,
              borderRadius: BorderRadius.circular(16),
              border: Border.all(color: Colors.grey.shade700),
            ),
            child: Column(
              mainAxisSize: MainAxisSize.min,
              children: [
                Icon(
                  Icons.face,
                  size: 48,
                  color: _messageColor,
                ),
                const SizedBox(height: 16),
                Text(
                  _message,
                  textAlign: TextAlign.center,
                  style: TextStyle(
                    color: _messageColor,
                    fontSize: 18,
                    fontWeight: FontWeight.w600,
                  ),
                ),
                const SizedBox(height: 16),
                Container(
                  padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
                  decoration: BoxDecoration(
                    color: Colors.black54,
                    borderRadius: BorderRadius.circular(8),
                  ),
                  child: const Text(
                    'Position face in frame ‚Ä¢ Look at camera ‚Ä¢ Stay still',
                    textAlign: TextAlign.center,
                    style: TextStyle(
                      color: Colors.white,
                      fontSize: 14,
                      fontWeight: FontWeight.w500,
                    ),
                  ),
                ),
              ],
            ),
          ),
        ],
      ),
    );
  }

  // üÜï NEW METHOD: Update employee with captured face images
  Future<void> _updateEmployeeWithFaceImage(
    EmployeeModel employee, 
    String imageUrl, 
    String type,
  ) async {
    try {
      final employeeProvider = context.read<EmployeeProvider>();
      
      // Create updated lists
      final newCheckinImages = List<String>.from(employee.faceCheckinImages);
      final newCheckoutImages = List<String>.from(employee.faceCheckoutImages);
      
      // Add to appropriate list
      if (type == 'checkin') {
        newCheckinImages.add(imageUrl);
        // Keep only last 10 images to prevent storage overflow
        if (newCheckinImages.length > 10) {
          newCheckinImages.removeAt(0);
        }
      } else if (type == 'checkout') {
        newCheckoutImages.add(imageUrl);
        // Keep only last 10 images to prevent storage overflow
        if (newCheckoutImages.length > 10) {
          newCheckoutImages.removeAt(0);
        }
      }
      
      // Create updated employee using copyWith
      final updatedEmployee = employee.copyWith(
        faceCheckinImages: newCheckinImages,
        faceCheckoutImages: newCheckoutImages,
        lastFaceCapture: DateTime.now(),
      );
      
      // Update in provider/database
      await employeeProvider.updateEmployee(updatedEmployee);
      print('‚úÖ DEBUG: Updated employee ${employee.fullName} with $type face image');
      
    } catch (e) {
      print('‚ùå DEBUG: Failed to update employee face image: $e');
      // Don't fail the entire check-in if image update fails
    }
  }

  @override
  void dispose() {
    // Stop camera stream first to prevent crashes
    _cameraController?.stopImageStream();
    _cameraController?.dispose();
    
    // Dispose animation controller
    _pulseController.dispose();
    
    // Close ML Kit resources
    _faceDetector.close();
    
    // Dispose face service (if it has a dispose method)
    try {
      _faceService.dispose();
    } catch (e) {
      // Ignore if dispose method doesn't exist
    }
    
    super.dispose();
  }
}
